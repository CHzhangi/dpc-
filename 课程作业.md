

课程作业

**sycl 作业一矩阵乘法。**

​	矩阵乘法是并行编程里面一个比较经典的问题，也是是科学计算的基本构建块。进行矩阵乘法我们知道就是第i行的所有元素各自乘以第j列的所有元素相加后得到坐标为（i,j）的矩阵元素。如果将该代码并行化，最简单的思路那就是针对单个result(i,j)遍历第i行和第j列相加得到结果，然后使用GPU进行并行加速。

​	由于之前学过一部分cuda，所以是先用cuda编写的代码，然后使用visual studio 2019里面的oneapi扩展

- Intel® oneAPI DPC++/C++ Compiler 
-  Intel® oneAPI DPC++ Compatibility Tool component）

进行migrate得到的DPc++的代码。***推荐***   使用这种方法进行cuda代码迁移。之前整了半天oneapi专门的迁移工具，环境感觉很麻烦，迁移后的代码要 经过一些检查和debug，不过大部分都是可以正确迁移的。下面是使用SYCL代码进行编写的矩阵乘法。

​	主要用到Intel的oneAPI工具集中的SYCL库来实现并行计算。SYCL是一种基于标准C++的编程模型，旨在提供对异构计算设备（如GPU、FPGA）的统一编程接口。代码中使用了SYCL的队列（`sycl::queue`）和并行计算（`sycl::parallel_for`）来将计算任务提交到设备上执行。为了在设备上分配内存，代码使用了SYCL的`malloc_device`函数，并在计算完成后使用`free`函数释放设备内存。

​	具体分析一下代码就是main函数中。

- 主要就是选择device，
- 然后在host端和设备端都为三个矩阵分配了内存。并且把host端的内容要复制到设备端。
- 然后调用DPC++上的parallel_for函数来进行并行计算。

其中`dpct::get_in_order_queue()` 返回一个 SYCL 队列对象，可以用于并行计算的任务调度。`parallel_for` 函数接受一个范围和一个 lambda 函数作为参数，用于指定并行计算的范围和计算操作。`sycl::nd_range<3>(numsblock * threadperblock, threadperblock)`：这行代码定义了并行计算的范围，使用 `nd_range<3>` 表示一个三维的范围。`numsblock * threadperblock` 表示每个维度的大小，这里是第一个维度和第二个维度的大小。`threadperblock` 表示第三个维度的大小，即工作组的大小。然后每个工作组都会执行 mulKernel，最后实现了并行化。

```c++
dpct::get_in_order_queue().parallel_for(
        sycl::nd_range<3>(numsblock * threadperblock, threadperblock),
        [=](sycl::nd_item<3> item_ct1) {
            mulKernel(m1_gpu, m2_gpu, result_gpu, m, n, k, item_ct1);
        });
```

关于优化的话个人感觉主要有两个方面。

一个是减少访存。由于在这里的代码我是针对每个元素都去访问了m1和m2,可以考虑使用共享内存，这个版本的DPC++版本还没Debug完，所以就没贴出来。

二是可以考虑每一次计算时，计算多个结果，而不是只计算一个元素，这样可以让启动的线程变少，在线程不够时效果比较好。但是由于在我自己的电脑上跑出来的时间更长了所以没有往下研究。

​	最后对于两个1600*1600的矩阵相乘，在自己电脑上的运行得到结果：![image-20231202140936384](C:\Users\adminis\AppData\Roaming\Typora\typora-user-images\image-20231202140936384.png)

```c++
#define blockW 4
void mulKernel(int *m1, int *m2, int *result, int m, int n, int k,
               const sycl::nd_item<3> &item_ct1)
{
/* DPCT_ORIG     int col = blockDim.x * blockIdx.x + threadIdx.x; 
计算当前工作项的列索引
*/
    int col = item_ct1.get_local_range(2) * item_ct1.get_group(2) +
              item_ct1.get_local_id(2);
/* DPCT_ORIG     int row = blockDim.y * blockIdx.y + threadIdx.y;
计算当前工作项的行索引
*/
    int row = item_ct1.get_local_range(1) * item_ct1.get_group(1) +
              item_ct1.get_local_id(1);
    int re = 0;
/*
遍历m1的row行和m2的col列，对应相乘然后累加。存到结果矩阵中。
*/
        for (int i = 0; i < n; i++) {
            re += m1[row * n + i] * m2[i * k + col];
        }
        int index = row * k + col;
        result[index] = re;
    
}
```

```c++
int main()
{
    int* m1;  //m*n
    int* m2;  //n*k
    int* result;
    // Add vectors in parallel.
    int m, n, k;
    m = 1600; n =800; k = 1600;
    clock_t start, stop;
    m1 = sycl::malloc_host<int>(m * n, dpct::get_in_order_queue());
    m2 = sycl::malloc_host<int>(k * n, dpct::get_in_order_queue());
    result = sycl::malloc_host<int>(m * k, dpct::get_in_order_queue());
    for (int i = 0; i < m; i++) {
        for (int j = 0; j < n; j++) {
            m1[i * n + j] = i;
        }
    }
    for (int i = 0; i < n; i++) {
        for (int j = 0; j < k; j++) {
            m2[i * k + j] = i;
        }
    }
    int* m1_gpu, * m2_gpu, * result_gpu;

	/*下面这段计算一下CPU进行矩阵乘法用时*/
    clock_t start2 = clock();
    for (int i = 0; i < m; i++) {
        for (int j = 0; j < k; j++) {
            result[i * k + j] = 0;
            for (int x = 0; x < n; x++) {
                result[i * k + j] += m1[i * n + x] * m2[x * k + j];
            }
        }
    }

    clock_t stop2 = clock();
    double elapsedTime = static_cast<double>(stop2 - start2) / CLOCKS_PER_SEC;

    // Print the result and execution time
    std::cout << "Matrix multiplication completed" << std::endl;
    std::cout << "Execution time: " << elapsedTime << " seconds" << std::endl;

    // Choose which GPU to run on, change this on a multi-GPU system.
    dpct::select_device(0);
    // Allocate GPU buffers for three vectors (two input, one output)    .
    m1_gpu = sycl::malloc_device<int>(m * n, dpct::get_in_order_queue());
    m2_gpu = sycl::malloc_device<int>(k * n, dpct::get_in_order_queue());
    result_gpu = sycl::malloc_device<int>(m * k, dpct::get_in_order_queue());

    // Copy input vectors from host memory to GPU buffers.
/* DPCT_ORIG     cudaMemcpy(m1_gpu, m1, m * n * sizeof(int),
 * cudaMemcpyHostToDevice);*/
    dpct::get_in_order_queue().memcpy(m1_gpu, m1, m * n * sizeof(int)).wait();
/* DPCT_ORIG     cudaMemcpy(m2_gpu, m2, n * k * sizeof(int),
 * cudaMemcpyHostToDevice);*/
    dpct::get_in_order_queue().memcpy(m2_gpu, m2, n * k * sizeof(int)).wait();
    // Launch a kernel on the GPU with one thread for each element.

    sycl::range<3> threadperblock(1, blockW, blockW);
    sycl::range<3> numsblock(1, (m + blockW - 1) / blockW,
                             (k + blockW - 1) / blockW);
    start = clock();
    dpct::get_in_order_queue().parallel_for(
        sycl::nd_range<3>(numsblock * threadperblock, threadperblock),
        [=](sycl::nd_item<3> item_ct1) {
            mulKernel(m1_gpu, m2_gpu, result_gpu, m, n, k, item_ct1);
        });
    dpct::get_current_device().queues_wait_and_throw();

    stop = clock();
    std::cout << "Block size: " << blockW << "x" << blockW << ", GPU TIME: " << (double)(stop - start) / CLOCKS_PER_SEC * 1000000.0 << " microseconds" << std::endl;
    // Copy output vector from GPU buffer to host memory.
/* DPCT_ORIG     cudaMemcpy(result, result_gpu, m * k * sizeof(int),
 * cudaMemcpyDeviceToHost);*/
    dpct::get_in_order_queue()
        .memcpy(result, result_gpu, m * k * sizeof(int))
        .wait();

    sycl::free(m1_gpu, dpct::get_in_order_queue());
    sycl::free(m2_gpu, dpct::get_in_order_queue());
    sycl::free(result_gpu, dpct::get_in_order_queue());
    
    std::ofstream file("result.txt");
    if (file) {
        for (int i = 0; i < m*k; ++i) {
            file << result[i] << " ";
        }
        file.close();
    }
    else {
        std::cerr << "Failed to open file for writing." << std::endl;
    }
    sycl::free(m1, dpct::get_in_order_queue());
    sycl::free(m2, dpct::get_in_order_queue());
    sycl::free(result, dpct::get_in_order_queue());
    return 0;
}
int sdiv(int x, int y) {
    if (y == 0) {
        return 0;
    }

    int result = (x + y - 1) / y;
    return result;
}
```

**sycl 作业二归并排序**

实现归并排序的GPU加速，我们知道归并排序主要的思想就是**分治**，也就是把一个大问题分解成多个小问题，小问题的求解之间是没有依赖关系的，因此可以用来并行化。并行化的主要思路就是将数组分成多段，然后把相邻两段合并，因为是多段，所以这个阶段可以并行处理。合并之后会继续迭代地合并，直到我们整个数组都排好序，也就是说仅剩一段数组。然后代码如下。

首先是Merge函数，主要在并行环境中进行归并排序的合并操作。首先根据当前的 SYCL 执行项计算出唯一的 `id`，用于确定当前执行项在整个并行计算中的唯一位置。然后，根据 `id` 计算出合并操作的起始索引和结束索引，以及存储结果的目标索引。其中，`index1` 和 `endIndex1` 表示第一个子数组的起始和结束索引，`index2` 和 `endIndex2` 表示第二个子数组的起始和结束索引，`targetIndex` 表示存储结果的目标索引。最后使用一个循环将两个子数组合并到临时数组中。

接下来是mergesort函数，函数中获取当前的设备并创建一个 SYCL 队列 `q_ct1`，以便在设备上执行并行计算。然后，使用 `sycl::malloc_device` 分配设备上的内存来存储排序算法所需的数组 `dev_a` 和 `dev_temp`。在循环中，迭代地调用`q_ct1.parallel_for` 来进行归并排序的每一轮合并操作。在并行执行的每个工作组内，调用 `merge` 函数来执行合并操作。合并操作的参数包括设备上的数组 `dev_a` 和 `dev_temp`、已排序的子数组大小 `sortedsize` 和待排序数组的总大小 `N`。



最后得到结果对102400长的数组进行归并排序，与调用sort库函数得到的结果是一样的，保证了正确性。

与串行版本cpu的归并排序结果对比如下：  可以看到结果和预期不符，推断是机器问题，在gpu上内存传输可能耗费了大部分时间。

![image-20231202154018473](C:\Users\adminis\AppData\Roaming\Typora\typora-user-images\image-20231202154018473.png)

```c++
#include <sycl/sycl.hpp>
#include <dpct/dpct.hpp>
using namespace std;
#include <cstdlib>
#include <stdio.h>
#include <iostream>
#include<windows.h>
#include<fstream>
#include<ctime>
#include<vector>
#include<algorithm>
void merge(int* a, int* temp, int sortedsize, int N,
                const sycl::nd_item<3> &item_ct1)
{
    // int id = blockIdx.x * blockDim.x + threadIdx.x;

    int blockid = item_ct1.get_group(0) * item_ct1.get_group_range(2) *
                      item_ct1.get_group_range(1) +
                  item_ct1.get_group(1) * item_ct1.get_group_range(2) +
                  item_ct1.get_group(2);
    int id = blockid * item_ct1.get_local_range(2) + item_ct1.get_local_id(2);

    unsigned long index1, index2, endIndex1, endIndex2, targetIndex;
    index1 = id * 2 * sortedsize;
    endIndex1 = index1 + sortedsize;
    index2 = endIndex1;
    endIndex2 = index2 + sortedsize;
    targetIndex = id * 2 * sortedsize;

    if (index1 >= N) return;

    if (endIndex1 > N)
    {
        endIndex1 = N;
        index2 = endIndex2 = N;
    }
    if (index2 > N)
    {
        index2 = endIndex2 = N;
    }
    if (endIndex2 > N)
        endIndex2 = N;
    int done = 0;
    while (!done)
    {
        if ((index1 == endIndex1) && (index2 < endIndex2))
            temp[targetIndex++] = a[index2++];
        else if ((index2 == endIndex2) && (index1 < endIndex1))
            temp[targetIndex++] = a[index1++];
        else if (a[index1] < a[index2])
            temp[targetIndex++] = a[index1++];
        else
            temp[targetIndex++] = a[index2++];

        if ((index1 == endIndex1) && (index2 == endIndex2))
            done = 1;
    }
}

int mergesort(int* data, int N, float& cost_time)
{
    dpct::device_ext &dev_ct1 = dpct::get_current_device();
    sycl::queue &q_ct1 = dev_ct1.in_order_queue();
    int* dev_a, * dev_temp;

    dev_a = sycl::malloc_device<int>(N, q_ct1);
    dev_temp = sycl::malloc_device<int>(N, q_ct1);
   q_ct1.memcpy(dev_a, data, sizeof(int) * N).wait();
    int blocks = 512;
    sycl::range<3> grids(1, 1, 128);
    float t0 = GetTickCount();
    int sortedsize = 1;
    while (sortedsize < N)
    {
        /*
        DPCT1049:0: The work-group size passed to the SYCL kernel may exceed the
        limit. To get the device limit, query info::device::max_work_group_size.
        Adjust the work-group size if needed.
        */
        q_ct1.parallel_for(
            sycl::nd_range<3>(grids * sycl::range<3>(1, 1, blocks),
                              sycl::range<3>(1, 1, blocks)),
            [=](sycl::nd_item<3> item_ct1) {
                merge(dev_a, dev_temp, sortedsize, N, item_ct1);
            });
        q_ct1.memcpy(dev_a, dev_temp, N * sizeof(int));
        sortedsize *= 2;
    }

    q_ct1.memcpy(data, dev_a, N * sizeof(int)).wait();
    cost_time = GetTickCount() - t0;
    sycl::free(dev_a, q_ct1);
   sycl::free(dev_temp, q_ct1);

    dev_ct1.queues_wait_and_throw();

    return 0;
}

int main(int argc, char* argv[])
{
    int N = 160000;
    int* data = new int[N];
    std::vector<int> data_vec;
    for (int k = 0; k < N; k++)
    {
        data[k] = rand() % 4096;
        data_vec.push_back(data[k]);
        //std::cout << data[k] << ",";
    }
    std::cout << std::endl;

    //float t0 = GetTickCount();
    float cost_gpu;
    mergesort(data, N, cost_gpu);
    //float t1 = GetTickCount();

    float tt0 = GetTickCount();
    mergeSort(data_vec, 0, data_vec.size() - 1);
    float tt1 = GetTickCount();

    int flag = 0;
    for (int k = 0; k < N; k++)
    {
        if (data[k] == data_vec[k])
        {
            flag++;
        }
    }
    std::cout << std::endl;
    std::cout << "check result (" << flag << "," << N << ") = " << (flag == N) << std::endl;

    std::cout << "gpu cost " << cost_gpu << "ms" << std::endl;
    std::cout << "cpu cost " << tt1 - tt0 << "ms" << std::endl;
    return 0;
}
```

作业三：图像卷积并⾏加速

​	图像卷积是一种常见的图像处理操作，用于应用各种滤波器和特征检测器。其原理可以简单地描述为在图像的每个像素上应用一个小的矩阵（通常称为卷积核或滤波器），并将卷积核中的元素与图像中对应位置的像素值相乘，然后将所有乘积的和作为结果。`convolution`函数接受输入图像、卷积核以及相关的尺寸参数，并在设备上执行矩阵卷积运算。最后，计算结果被复制回主机内存并存储在`output`向量中。

​	下文也是用了Intel的oneAPI工具集中的SYCL库来实现并行计算。首先是定义了一个卷积函数。每个工作项负责计算输出图像的一个卷积后的像素。然后在convolution函数中多次调用卷积函数。

- 使用SYCL的`parallel_for`函数来启动并行计算。指定工作项的范围和工作组大小。

- 在内核函数中，可以使用`nd_item`对象获取工作项的索引和工作组信息，以便确定要计算的像素位置。

  最后一部分就是使用`memcpy`函数将计算得到的输出结果从设备内存复制回主机内存中存储的输出向量中并释放相关内存。

  最后得到的结果经过验证也是正确的。

```c++
#include <sycl/sycl.hpp>
#include <dpct/dpct.hpp>
#include <iostream>
#include <vector>

void convolutionKernel(const int* input, const int* kernel, int* output, int inputWidth, int inputHeight, int kernelWidth, int kernelHeight, int outputWidth, int outputHeight,
                       const sycl::nd_item<3> &item_ct1)
{
    int x = item_ct1.get_group(2) * item_ct1.get_local_range(2) +
            item_ct1.get_local_id(2);
    int y = item_ct1.get_group(1) * item_ct1.get_local_range(1) +
            item_ct1.get_local_id(1);

    if (x < outputWidth && y < outputHeight)
    {
        int sum = 0;
        for (int ky = 0; ky < kernelHeight; ky++)
        {
            for (int kx = 0; kx < kernelWidth; kx++)
            {
                int inputX = x + kx;
                int inputY = y + ky;
                sum += input[inputY * inputWidth + inputX] * kernel[ky * kernelWidth + kx];
            }
        }
        output[y * outputWidth + x] = sum;
    }
}

// 定义卷积函数
void convolution(const std::vector<int>& input, const std::vector<int>& kernel, std::vector<int>& output, int inputWidth, int inputHeight, int kernelWidth, int kernelHeight)
{
    sycl::device dev_ct1;
    sycl::queue q_ct1(dev_ct1,
                      sycl::property_list{sycl::property::queue::in_order()});
    int outputWidth = inputWidth - kernelWidth + 1;
    int outputHeight = inputHeight - kernelHeight + 1;
    int inputSize = inputWidth * inputHeight * sizeof(int);
    int kernelSize = kernelWidth * kernelHeight * sizeof(int);
    int outputSize = outputWidth * outputHeight * sizeof(int);

    // 在设备上分配内存
    int* d_input;
    int* d_kernel;
    int* d_output;
    d_input = (int *)sycl::malloc_device(inputSize, q_ct1);
    d_kernel = (int *)sycl::malloc_device(kernelSize, q_ct1);
    d_output = (int *)sycl::malloc_device(outputSize, q_ct1);

    // 将输入数据复制到设备内存
    q_ct1.memcpy(d_input, input.data(), inputSize).wait();
    q_ct1.memcpy(d_kernel, kernel.data(), kernelSize).wait();

    sycl::range<3> blockSize(1, 16, 16);
    sycl::range<3> gridSize(1, (outputHeight + blockSize[1] - 1) / blockSize[1],
                            (outputWidth + blockSize[2] - 1) / blockSize[2]);

    /*
    DPCT1049:0: The work-group size passed to the SYCL kernel may exceed the
    limit. To get the device limit, query info::device::max_work_group_size.
    Adjust the work-group size if needed.
    */
    q_ct1.parallel_for(sycl::nd_range<3>(gridSize * blockSize, blockSize),
                       [=](sycl::nd_item<3> item_ct1) {
                           convolutionKernel(
                               d_input, d_kernel, d_output, inputWidth,
                               inputHeight, kernelWidth, kernelHeight,
                               outputWidth, outputHeight, item_ct1);
                       });

    // 将计算结果复制回主机内存
    q_ct1.memcpy(output.data(), d_output, outputSize).wait();

    // 释放设备内存
    sycl::free(d_input, q_ct1);
    sycl::free(d_kernel, q_ct1);
    sycl::free(d_output, q_ct1);
}

void test()
{
    // 定义输入图像和卷积核
    std::vector<int> input = { 1, 2, 3, 4, 5,
                               6, 7, 8, 9, 10,
                               11, 12, 13, 14, 15,
                               16, 17, 18, 19, 20,
                               21, 22, 23, 24, 25 };
    std::vector<int> kernel = { 1, 5, -1,
                                2, 0, -2,
                                1, 0, -1 };

    int inputWidth = 5;
    int inputHeight = 5;
    int kernelWidth = 3;
    int kernelHeight = 3;
    int outputWidth = inputWidth - kernelWidth + 1;
    int outputHeight = inputHeight - kernelHeight + 1;

    // 创建输出图像
    std::vector<int> output(outputWidth * outputHeight);

    // 进行卷积运算
    convolution(input, kernel, output, inputWidth, inputHeight, kernelWidth, kernelHeight);

    // 打印输出图像
    for (int y = 0; y < outputHeight; y++)
    {
        for (int x = 0; x < outputWidth; x++)
        {
            std::cout << output[y * outputWidth + x] << " ";
        }
        std::cout << std::endl;
    }
}

int main()
{
    test();
    return 0;
}
```

